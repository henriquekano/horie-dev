<HTML>
<HEAD>
<META name=vsisbn content="0471503363">
<META name=vstitle content="Art of Computer Systems Performance Analysis Techniques For Experimental Design Measurements Simulation And Modeling">
<META name=vsauthor content="Raj Jain">
<META name=vsimprint content="Wiley Computer Publishing">
<META name=vspublisher content="John Wiley & Sons, Inc.">
<META name=vspubdate content="05/01/91">
<META name=vscategory content="Web and Software Development: Software Engineering: Simulation and Modeling">







<TITLE>The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling:Other Regression Models</TITLE>

<!-- HEADER -->

<STYLE type="text/css"> 
 <!--
 A:hover  {
 	color : Red;
 }
 -->
</STYLE>

<META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">

<!--ISBN=0471503363//-->
<!--TITLE=The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling//-->
<!--AUTHOR=Raj Jain//-->
<!--PUBLISHER=Wiley Computer Publishing//-->
<!--CHAPTER=15//-->
<!--PAGES=248-251//-->
<!--UNASSIGNED1//-->
<!--UNASSIGNED2//-->

<CENTER>
<TABLE BORDER>
<TR>
<TD><A HREF="15-01.html">Previous</A></TD>
<TD><A HREF="../ewtoc.html">Table of Contents</A></TD>
<TD><A HREF="15-03.html">Next</A></TD>
</TR>
</TABLE>
</CENTER>
<P><BR></P>
<P>We would like to find a linear function to estimate the CPU time:
</P>
<P>CPU time = <I>b</I><SUB><SMALL>0</SMALL></SUB> &#43; <I>b</I><SUB><SMALL>1</SMALL></SUB>(number of disk I/O&#146;s) &#43; <I>b</I><SUB><SMALL>2</SMALL></SUB>(memory size)</P>
<P>In this case,</P>
<P ALIGN="CENTER"><IMG SRC="images/15-03d.jpg"></P>
</IMGD>
<P>The regression parameters are:
</P>
<P ALIGN="CENTER"><B>b</B> = (<B>X</B><SUP><SMALL>T</SMALL></SUP><B>X</B>)<SUP><SMALL>&#150;1</SMALL></SUP><B>X</B><SUP><SMALL>T</SMALL></SUP><B>y</B> = (&#150;0.1614,0.1182,0.0265)<SUP><SMALL>T</SMALL></SUP></P>
<P>The regression equation is</P>
<P>CPU time = &#150; 0.1614 &#43; 0.1182(number of disk I/O&#146;s) &#43; 0.0265(memory size)</P>
<P>Using this equation, we can estimate CPU time and compute the errors as shown in Table 15.2. From the table we see that</P>
<P><P ALIGN="CENTER"><IMG SRC="images/15-04d.jpg"></P>
</IMGD></P>
<P>An alternate method to compute SSE is</P>
<P ALIGN="CENTER">SSE = <B>{y<SUP><SMALL>T</SMALL></SUP>y &#150; b<SUP><SMALL>T</SMALL></SUP>X<SUP><SMALL>T</SMALL></SUP>y}</B></P>
<P>For this data,</P>
<P><P ALIGN="CENTER"><IMG SRC="images/15-05d.jpg"></P>
</IMGD></P>
<TABLE WIDTH="100%"><TR>
<TH CAPTION VALIGN="TOP" ALIGN="LEFT" COLSPAN="6">TABLE 15.2 Error Computation for the Disk-Memory-CPU Data
<TR>
<TD COLSPAN="6"><HR>
<TR>
<TH VALIGN="BOTTOM" ALIGN="CENTER" WIDTH="15%">CPU Time,<BR><I>y</I><SUB><SMALL><I>i</I></SMALL></SUB>
<TH VALIGN="BOTTOM" ALIGN="CENTER" WIDTH="15%">Disk I/O&#146;s,<BR><I>x</I><SUB><SMALL>1<I>i</I></SMALL></SUB>
<TH VALIGN="BOTTOM" ALIGN="CENTER" WIDTH="15%">Memory Size, <I>x</I><SUB><SMALL>2<I>i</I></SMALL></SUB>
<TH VALIGN="BOTTOM" ALIGN="CENTER" WIDTH="15%">Estimated<BR>CPU time,<BR><IMG SRC="images/15-11i.jpg"></IMGI>
<TH VALIGN="BOTTOM" ALIGN="CENTER" WIDTH="15%">Error,<BR> <I>e</I><SUB><SMALL><I>i</I></SMALL></SUB>
<TH VALIGN="BOTTOM" ALIGN="CENTER">Error<BR>Squared,<BR><I>e</I><SUP><SMALL>2</SMALL></SUP><SUB><SMALL><I>i</I></SMALL></SUB>
<TR>
<TD COLSPAN="6"><HR>
<TR>
<TD VALIGN="TOP" ALIGN="CENTER">2
<TD VALIGN="TOP" ALIGN="CENTER">14
<TD VALIGN="TOP" ALIGN="CENTER">70
<TD VALIGN="TOP" ALIGN="CENTER">3.3490
<TD VALIGN="TOP" ALIGN="CENTER">&#150;1.3490
<TD VALIGN="TOP" ALIGN="CENTER">1.8198
<TR>
<TD VALIGN="TOP" ALIGN="CENTER">5
<TD VALIGN="TOP" ALIGN="CENTER">16
<TD VALIGN="TOP" ALIGN="CENTER">75
<TD VALIGN="TOP" ALIGN="CENTER">3.718D
<TD VALIGN="TOP" ALIGN="CENTER">1.2820
<TD VALIGN="TOP" ALIGN="CENTER">1.6436
<TR>
<TD VALIGN="TOP" ALIGN="CENTER">7
<TD VALIGN="TOP" ALIGN="CENTER">27
<TD VALIGN="TOP" ALIGN="CENTER">144
<TD VALIGN="TOP" ALIGN="CENTER">6.8472
<TD VALIGN="TOP" ALIGN="CENTER">0.1528
<TD VALIGN="TOP" ALIGN="CENTER">0.0233
<TR>
<TD VALIGN="TOP" ALIGN="CENTER">9
<TD VALIGN="TOP" ALIGN="CENTER">42
<TD VALIGN="TOP" ALIGN="CENTER">190
<TD VALIGN="TOP" ALIGN="CENTER">9.8400
<TD VALIGN="TOP" ALIGN="CENTER">&#150;0.8400
<TD VALIGN="TOP" ALIGN="CENTER">0.7053
<TR>
<TD VALIGN="TOP" ALIGN="CENTER">10
<TD VALIGN="TOP" ALIGN="CENTER">39
<TD VALIGN="TOP" ALIGN="CENTER">210
<TD VALIGN="TOP" ALIGN="CENTER">10.0151
<TD VALIGN="TOP" ALIGN="CENTER">&#150;0.0151
<TD VALIGN="TOP" ALIGN="CENTER">0.0002
<TR>
<TD VALIGN="TOP" ALIGN="CENTER">13
<TD VALIGN="TOP" ALIGN="CENTER">50
<TD VALIGN="TOP" ALIGN="CENTER">235
<TD VALIGN="TOP" ALIGN="CENTER">11.9783
<TD VALIGN="TOP" ALIGN="CENTER">1.0217
<TD VALIGN="TOP" ALIGN="CENTER">1.0439
<TR>
<TD VALIGN="TOP" ALIGN="CENTER"><U>20</U>
<TD VALIGN="TOP" ALIGN="CENTER"><U>83</U>
<TD VALIGN="TOP" ALIGN="CENTER"><U>400</U>
<TD VALIGN="TOP" ALIGN="CENTER"><U>20.2529</U>
<TD VALIGN="TOP" ALIGN="CENTER"><U>&#150;0.2529</U>
<TD VALIGN="TOP" ALIGN="CENTER"><U>0.0639</U>
<TR>
<TD VALIGN="TOP" ALIGN="CENTER">66
<TD VALIGN="TOP" ALIGN="CENTER">271
<TD VALIGN="TOP" ALIGN="CENTER">1324
<TD VALIGN="TOP" ALIGN="CENTER">66.0000
<TD VALIGN="TOP" ALIGN="CENTER">&#150;0.0003
<TD VALIGN="TOP" ALIGN="CENTER">5.3000
<TR>
<TD COLSPAN="6"><HR>
<TR>
</TABLE>
<P>Therefore,
</P>
<P ALIGN="CENTER">SST = SSY &#150; SS0 = 828 &#150; 622.29 = 205.71</P>
<P ALIGN="CENTER">SSR = SST &#150; SSE = 205.71 &#150; 5.3 = 200.41</P>
<P>The coefficient of determination is</P>
<P><P ALIGN="CENTER"><IMG SRC="images/15-06d.jpg"></P>
</IMGD></P>
<P>Thus, the regression explains 97% of the variation of <I>y</I>.</P>
<P>The coefficient of multiple correlation is defined as the square root of the coefficient of determination. For this example, it is given by</P>
<P><P ALIGN="CENTER"><IMG SRC="images/15-07d.jpg"></P>
</IMGD></P>
<P>The standard deviation of errors is</P>
<P><P ALIGN="CENTER"><IMG SRC="images/15-08d.jpg"></P>
</IMGD></P>
<P>The standard deviations of the regression parameters are <P>Estimated standard deviation of <I>b</I><SUB><SMALL>0</SMALL></SUB> <IMG SRC="images/15-12i.jpg"></IMGI></P>
<P>Estimated standard deviation of <I>b</I><SUB><SMALL>1</SMALL></SUB> <IMG SRC="images/15-13i.jpg"></IMGI></P>
<P>Estimated standard deviation of <I>b</I><SUB><SMALL>2</SMALL></SUB> <IMG SRC="images/15-14i.jpg"></IMGI></P>
<P>The 0.95-quantile for a <I>t</I>-variate with four degrees of freedom is 2.132. The confidence intervals for the regression parameters are therefore</P>
<P>90% confidence interval of <I>b</I><SUB><SMALL>0</SMALL></SUB> = <IMG SRC="images/15-15i.jpg"></IMGI></P>
<P>90% confidence interval of <I>b</I><SUB><SMALL>1</SMALL></SUB> = <IMG SRC="images/15-16i.jpg"></IMGI></P>
<P>90% confidence interval of <I>b</I><SUB><SMALL>2</SMALL></SUB> = <IMG SRC="images/15-17i.jpg"></IMGI></P>
<P>We see that none of the three parameters is significant at a 90% confidence level. In order to illustrate the applications of the prediction formula, let us predict a single future observation for programs with 100 disk Ws and a memory size of 550. The predicted mean <I>y</I><SUB><SMALL>1<I>p</I></SMALL></SUB> is given by</P>
<P><I>y</I><SUB><SMALL>1<I>p</I></SMALL></SUB> = <I>b</I><SUB><SMALL>0</SMALL></SUB> &#43;<I>b</I><SUB><SMALL>1</SMALL></SUB><I>x</I><SUB><SMALL>1</SMALL></SUB> &#43; <I>b</I><SUB><SMALL>2</SMALL></SUB><I>x</I><SUB><SMALL>2</SMALL></SUB> = &#150;0.1614 &#43; 0.1182(100) &#43; 0.0265(550) =26.2375</P>
<P>The standard deviation of the predicted observation is</P>
<P><P ALIGN="CENTER"><IMG SRC="images/15-09d.jpg"></P>
</IMGD></P>
<P>The 90% confidence interval using the <I>t</I>-value of 2.132 is</P>
<P ALIGN="CENTER"><IMG SRC="images/15-10d.jpg"></P>
</IMGD>
<P>The standard deviation for a mean of a large number of observations is
</P>
<P><P ALIGN="CENTER"><IMG SRC="images/15-11d.jpg"></P>
</IMGD></P>
<P>The 90% confidence interval is</P>
<P><P ALIGN="CENTER"><IMG SRC="images/15-12d.jpg"></P>
</IMGD></P>
<H4 ALIGN="LEFT"><A NAME="Heading3"></A><FONT COLOR="#000077">15.1.1 Analysis of Variance</FONT></H4>
<P>The partitioning of variation into an explained and unexplained part is useful in practice since it can be easily presented by the analyst to the decision makers. For example, it is easy for them to understand that a regression that explains only 709/6 of the variation is not as good as one that explains 90%. The next question is how much explained variation is good? A statistical answer to this question is obtained by the so-called <B>Analysis of Variance (ANOVA).</B> This analysis essentially tests the hypothesis that the SSR is less than or equal to the SSE.</P>
<P>Various sums of squares are related as follows:</P>
<P ALIGN="CENTER">SST = SSY &#150; SS0 = SSR &#43; SSE</P>
<P>Each of the sums of squares has an associated degree of freedom that corresponds to the number of independent values required to compute them. The SSY has <I>n</I> degrees of freedom since each of its n observations can be independently chosen. Ala SSE has only <I>n</I> &#150; <I>k</I> &#150; 1 degrees of freedom since it is obtained after calculating <I>k</I> &#43; 1 regression parameters from the data. Similarly, the SST has <I>n</I> &#150; 1 degrees of freedom since one parameter <IMG SRC="images/15-18i.jpg"></IMGI> must be calculated from the data before the SST can be computed. The SSR, which is the difference between the SST and the SSE, has the remaining <I>k</I> degrees of freedom. Thus, various sums and their associated degrees of freedom are as follows:</P>
<P ALIGN="CENTER">SST = SSY &#150; SS0 SSR &#43; SSE</P>
<P ALIGN="CENTER"><I>n</I> &#150; 1 = <I>n</I> &#150; 1 <I>k</I> &#43; (<I>n</I> &#150; <I>k</I> &#150; 1)</P>
<P>Notice that the degrees of freedom add in a manner similar to the sum of squares. This fact can be used to check if the degrees of freedoms have been assigned correctly.</P>
<P>Assuming that the errors are independent and normally distributed and that all of them are identically distributed (with the same mean and variance), it follows that the <I>y</I>&#146;s are also normally distributed since the <I>x</I>&#146;s are nonstochastic (they can be measured without errors). The sum of squares of normal variates has a chi-square distribution (see Section 29.4). Thus, various sums of squares have a chi-square distribution with the degrees of freedoms as given above.</P>
<P>Given two sums of squares SS<I>i</I> and SS<I>j</I> with <I>v</I><SUB><SMALL><I>i</I></SMALL></SUB> and <I>v</I><SUB><SMALL><I>j</I></SMALL></SUB> degrees of freedom, the ratio (SS<I>i</I>/<I>v</I><SUB><SMALL><I>i</I></SMALL></SUB>)/(SS<I>j</I>/<I>v</I><SUB><SMALL><I>j</I></SMALL></SUB>) has an <I>F</I> distribution with <I>v</I><SUB><SMALL><I>i</I></SMALL></SUB> numerator degrees of freedom and <I>v</I><SUB><SMALL><I>j</I></SMALL></SUB> denominator degrees of freedom. This follows from the definition of the <I>F</I> distribution as explained in Section 29.7 The hypothesis that the sum SS<I>i</I> is less than or equal to SS<I>j</I> is rejected at the &#945; significance level if the ratio is greater than the 1 &#150; &#945; quantile of the <I>F</I>-variate. Thus, the computed ratio is compared with <I>F</I><SUB><SMALL>[1&#150;&#945;;<I>v</I><SUB><I>i</I></SMALL></SUB>,<I>v</I><SUB><SMALL><I>j</I></SMALL></SUB>]</SUB> obtained from the table of <I>F</I> quantiles (Tables A.6 to A.8 in the Appendix) and the sums of squares are considered significantly different if the computed <I>F</I> is more than that obtained from the table. This procedure is also known as in <B><I>F</I>-test.</B></P><P><BR></P>
<CENTER>
<TABLE BORDER>
<TR>
<TD><A HREF="15-01.html">Previous</A></TD>
<TD><A HREF="../ewtoc.html">Table of Contents</A></TD>
<TD><A HREF="15-03.html">Next</A></TD>
</TR>
</TABLE>
</CENTER>

<hr width="90%" size="1" noshade>
<div align="center">
<font face="Verdana,sans-serif" size="1">Copyright &copy; <a href="/reference/wiley00001.html">John Wiley &amp; Sons, Inc.</a></font>
</div>
<!-- all of the reference materials (books) have the footer and subfoot reveresed -->
<!-- reference_subfoot = footer -->
<!-- reference_footer = subfoot -->

</BODY>
</HTML>

<!-- END FOOTER -->

