<HTML>
<HEAD>
<META name=vsisbn content="0471503363">
<META name=vstitle content="Art of Computer Systems Performance Analysis Techniques For Experimental Design Measurements Simulation And Modeling">
<META name=vsauthor content="Raj Jain">
<META name=vsimprint content="Wiley Computer Publishing">
<META name=vspublisher content="John Wiley & Sons, Inc.">
<META name=vspubdate content="05/01/91">
<META name=vscategory content="Web and Software Development: Software Engineering: Simulation and Modeling">







<TITLE>The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling:Capacity Planning and Benchmarking</TITLE>

<!-- HEADER -->

<STYLE type="text/css"> 
 <!--
 A:hover  {
 	color : Red;
 }
 -->
</STYLE>

<META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">

<!--ISBN=0471503363//-->
<!--TITLE=The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling//-->
<!--AUTHOR=Raj Jain//-->
<!--PUBLISHER=Wiley Computer Publishing//-->
<!--CHAPTER=09//-->
<!--PAGES=130-133//-->
<!--UNASSIGNED1//-->
<!--UNASSIGNED2//-->

<CENTER>
<TABLE BORDER>
<TR>
<TD><A HREF="09-02.html">Previous</A></TD>
<TD><A HREF="../ewtoc.html">Table of Contents</A></TD>
<TD><A HREF="09-04.html">Next</A></TD>
</TR>
</TABLE>
</CENTER>
<P><BR></P>
<P>The above list includes only those mistakes that an analyst may make inadvertently due to inexperience. The benchmarking tricks that have been used by experienced analysts to show the superiority of their systems are discussed in the next section.
</P>
<H3><A NAME="Heading5"></A><FONT COLOR="#000077">9.4 BENCHMARKING GAMES</FONT></H3>
<P>Benchmarking is the process of comparing two systems using standard well-known benchmarks. The process is not always carried out fairly. Some of the ways that the results of a benchmarking study may be misleading or biased are discussed next.
</P>
<DL>
<DD><B>1.</B>&nbsp;&nbsp;<I>Differing configurations may be used to run the same workload on two systems.</I> The configurations may have a different amount of memory, different disks, or different number of disks.
<DD><B>2.</B>&nbsp;&nbsp;<I>The compilers may be wired to optimize the workload.</I> In one case, the compiler totally eliminated the main loop in the synthetic program, thereby giving infinitely better performance than other systems.
<DD><B>3.</B>&nbsp;&nbsp;<I>Test specifications may be written so that they are biased toward one machine.</I> This may happen if the specifications are written based upon an existing environment without consideration to generalizing the requirements for different vendors.
<DD><B>4.</B>&nbsp;&nbsp;<I>A synchronized job sequence may be used.</I> It is possible to manipulate a job sequence so that CPU-bound and I/O-bound steps synchronize to give a better overall performance.
<DD><B>5.</B>&nbsp;&nbsp;<I>The workload may be arbitrarily picked.</I> Many of the well-known kernels, such as sieve and puzzle, have not been verified to be representative of the real-world applications.
<DD><B>6.</B>&nbsp;&nbsp;<I>Very small benchmarks may be used.</I> Such benchmarks give 100% cache hits, thereby ignoring the inefficiency of memory and cache organizations. Small benchmarks may also not show the effect of I/O overhead and context switching. The results will depend mainly on the few instructions that occur in the inner loop. By judicious choice of instructions in the loop, the results can be skewed by any amount desired.
<BR>Most real systems make use of a wide variety of workloads. To compare two systems, one should therefore use as many workloads as possible. By using only a few selected benchmarks, the results can be biased, as desired.
<DD><B>7.</B>&nbsp;&nbsp;<I>Benchmarks may be manually translated to optimize the performance.</I> Often benchmarks need to be manually translated to make them runable on different systems. The performance may then depend more on the ability of the translator than on the system under test.
</DL>
<H3><A NAME="Heading6"></A><FONT COLOR="#000077">9.5 LOAD DRIVERS</FONT></H3>
<P>In order to measure the performance of a computer system, it is necessary to have some means of putting loads on the system. Although our interest in load drivers here is purely for performance measurement, it must be pointed out that the same load drivers can also be used for other purposes, such as the following:
</P>
<P><A NAME="Fig2"></A><A HREF="javascript:displayWindow('images/09-02.jpg',500,107 )"><IMG SRC="images/09-02t.jpg"></A>
<BR><A HREF="javascript:displayWindow('images/09-02.jpg',500,107)"><FONT COLOR="#000077"><B>FIGURE 9.2</B></FONT></A>&nbsp;&nbsp;An RTE and a SUT.</P>
<DL>
<DD><B>&#149;</B>&nbsp;&nbsp;<I>Component Certification:</I> This requires rigorous testing of hardware and software components by imposing sequential and random combinations of workload demands.
<DD><B>&#149;</B>&nbsp;&nbsp;<I>System Integration:</I> This involves verifying that various hardware and software components of distributed systems work compatibly under different environments.
<DD><B>&#149;</B>&nbsp;&nbsp;<I>Stress-Load Analysis:</I> This requires putting high loads on the system to test for stable and error-free operation at these loads.
<DD><B>&#149;</B>&nbsp;&nbsp;<I>Regression Testing:</I> After every change in the system, the new version of the system should be tested to demonstrate that all previous capabilities are functional along with the new ones.
</DL>
<P>Three techniques that have been used for load driving are using internal drivers, live operators, or remote-terminal emulators.
</P>
<P>The <B>internal-driver</B> method consists of loading programs directly into the memory and executing. If there is more than one program per user, then the whole sequence of commands is put in a disk file and run as a batch job. The main problem with the internal-driver method is that the effect of the terminal communication overhead is not visible. Also, the loading overhead may affect the system performance.</P>
<P>One way to account for terminal communication overhead is to have <B>live operators</B> utilize the system. To test a multiuser system, many people would need to sit down at their own terminal and execute a predetermined set of commands. This is a costly process and one that is difficult to control. The presence of the human element in the measurement increases the variance of the result. The increased variance means more trials are required to obtain a desired level of confidence.</P>
<P>The most desirable and popular method for putting the load on the system is to make use of computers. One computer can generally simulate many users in a very controlled and repeatable fashion. These computers are called <B>Remote-Terminal Emulators (RTEs)</B> (see Figure 9.2). The remainder of this chapter discusses the design and use of RTEs.</P>
<H3><A NAME="Heading7"></A><FONT COLOR="#000077">9.6 REMOTE-TERMINAL EMULATION</FONT></H3>
<P>An RTE emulates the terminals, the terminal communication equipments, the operators, and the requests to be submitted to the System Under Test (SUT), as shown in Figure 9.3. In general, the RTE is a full-fledged computer that includes disks, magtapes, and at least one console terminal. In many cases, the RTE may be more powerful than the SUT. For example, super-minicomputers may be used to drive minicomputers and workstations. Most RTEs have their own operating system designed specifically for this real-time operation.
</P>
<P><A NAME="Fig3"></A><A HREF="javascript:displayWindow('images/09-03.jpg',500,229 )"><IMG SRC="images/09-03t.jpg"></A>
<BR><A HREF="javascript:displayWindow('images/09-03.jpg',500,229)"><FONT COLOR="#000077"><B>FIGURE 9.3</B></FONT></A>&nbsp;&nbsp;Compenents emulated by an RTE</P>
<P><A NAME="Fig4"></A><A HREF="javascript:displayWindow('images/09-04.jpg',500,109 )"><IMG SRC="images/09-04t.jpg"></A>
<BR><A HREF="javascript:displayWindow('images/09-04.jpg',500,109)"><FONT COLOR="#000077"><B>FIGURE 9.4</B></FONT></A>&nbsp;&nbsp;Sample scenario.</P>
<P>The RTE sends commands to the SUT at appropriate intervals. The user commands are read from a disk file called script. The script file contains user commands as well as other instructions for the RTE, such as when the RTE should send out a command.
</P>
<P>Scripts written for one RTE system cannot be used on another RTE system because they may include an incompatible set of commands. For the same reason, scripts that are written for one SUT cannot be used on another SUT. To compare two incompatible SLITS, the workload should be first described in a manner independent of the SUT and RTE. This description is called a <B>scenario.</B> An example of a scenario is shown in Figure 9.4.</P><P><BR></P>
<CENTER>
<TABLE BORDER>
<TR>
<TD><A HREF="09-02.html">Previous</A></TD>
<TD><A HREF="../ewtoc.html">Table of Contents</A></TD>
<TD><A HREF="09-04.html">Next</A></TD>
</TR>
</TABLE>
</CENTER>

<hr width="90%" size="1" noshade>
<div align="center">
<font face="Verdana,sans-serif" size="1">Copyright &copy; <a href="/reference/wiley00001.html">John Wiley &amp; Sons, Inc.</a></font>
</div>
<!-- all of the reference materials (books) have the footer and subfoot reveresed -->
<!-- reference_subfoot = footer -->
<!-- reference_footer = subfoot -->

</BODY>
</HTML>

<!-- END FOOTER -->

